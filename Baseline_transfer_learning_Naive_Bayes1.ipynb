{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import time\n",
    "# Install a few python packages using pip\n",
    "from common import utils\n",
    "utils.require_package('nltk')\n",
    "utils.require_package(\"wget\")      # for fetching dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/arunima/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys, time\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "# Numerical manipulation libraries.\n",
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Helper libraries\n",
    "from common import utils, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to read the amazon review data files\n",
    "def parse(path):\n",
    "  print('start parse')\n",
    "  start_parse = time.time()\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "  end_parse = time.time()\n",
    "  print('end parse with time for parse',end_parse - start_parse)\n",
    "\n",
    "def getDF(path):\n",
    "  print('start getDF')\n",
    "  start = time.time()\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  print('end getDF')\n",
    "  end = time.time()\n",
    "  print('time taken to load data = ',end-start)\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "#df = getDF('reviews_Toys_and_Games.json.gz') #old def function corresponding to the step bt step vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 81.08209609985352\n",
      "end getDF\n",
      "time taken to load data =  81.08266162872314\n",
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 112.94878482818604\n",
      "end getDF\n",
      "time taken to load data =  112.94914507865906\n"
     ]
    }
   ],
   "source": [
    "df_vid = getDF('reviews_Video_Games.json.gz')\n",
    "df_toys = getDF('reviews_Toys_and_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 65.77880191802979\n",
      "end getDF\n",
      "time taken to load data =  65.78030347824097\n"
     ]
    }
   ],
   "source": [
    "df_aut = getDF('reviews_Automotive.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 225.31836080551147\n",
      "end getDF\n",
      "time taken to load data =  225.31877446174622\n"
     ]
    }
   ],
   "source": [
    "df_hnk = getDF('reviews_Home_and_Kitchen.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Toys reviews summary\n",
      "(2252771, 9)\n",
      "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
      "       'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
      "      dtype='object')\n",
      "       reviewerID        asin   reviewerName helpful  \\\n",
      "0   AMEVO2LY6VEJA  0000191639  Nicole Soeder  [0, 0]   \n",
      "1  A3C9CSW3TJITGT  0005069491          Renee  [0, 0]   \n",
      "2  A31POTIYCKSZ9G  0076561046  So CA Teacher  [0, 0]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  Great product, thank you! Our son loved the pu...      5.0   \n",
      "1  I love these felt nursery rhyme characters and...      4.0   \n",
      "2  I see no directions for its use. Therefore I h...      3.0   \n",
      "\n",
      "                                      summary  unixReviewTime   reviewTime  \n",
      "0                                     Puzzles      1388016000  12 26, 2013  \n",
      "1  Charming characters but busy work required      1377561600  08 27, 2013  \n",
      "2                    No directions for use...      1404864000   07 9, 2014  \n",
      "\n",
      " Video games reviews summary\n",
      "(1324753, 9)\n",
      "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
      "       'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
      "      dtype='object')\n",
      "       reviewerID        asin        reviewerName helpful  \\\n",
      "0   AB9S9279OZ3QO  0078764343                Alan  [1, 1]   \n",
      "1  A24SSUT5CSW8BH  0078764343     Kindle Customer  [0, 0]   \n",
      "2   AK3V0HEBJMQ7J  0078764343  Miss Kris \"Krissy\"  [0, 0]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  I haven't gotten around to playing the campaig...      5.0   \n",
      "1  I want to start off by saying I have never pla...      5.0   \n",
      "2  this will be my second medal of honor I love h...      4.0   \n",
      "\n",
      "                       summary  unixReviewTime   reviewTime  \n",
      "0  Good game and Beta access!!      1373155200   07 7, 2013  \n",
      "1                Love the game      1377302400  08 24, 2013  \n",
      "2                     MOH nice      1372896000   07 4, 2013  \n",
      "\n",
      " Auto reviews summary\n",
      "(1373768, 9)\n",
      "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
      "       'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
      "      dtype='object')\n",
      "       reviewerID        asin   reviewerName helpful  \\\n",
      "0  A108J5O7DG2WIM  0219400083     Julio Csar  [0, 0]   \n",
      "1  A1QBLUSZW281TA  0715000322  Angelo Aresco  [0, 0]   \n",
      "2  A3B40ZIZJ3HEP7  0970408641        derrick  [1, 1]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  I loved the look and the great improvement at ...      4.0   \n",
      "1  Put these on my 2011 can am outlander 800xt, e...      5.0   \n",
      "2  Don't buy this item  , its not a 4 window roll...      1.0   \n",
      "\n",
      "                           summary  unixReviewTime   reviewTime  \n",
      "0  Great improvement for my Spyder      1376697600  08 17, 2013  \n",
      "1            Warm and toasty hands      1396915200   04 8, 2014  \n",
      "2                          garbage      1332115200  03 19, 2012  \n",
      "\n",
      " Home and Kitchen reviews summary\n",
      "(4253926, 9)\n",
      "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
      "       'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
      "      dtype='object')\n",
      "       reviewerID        asin reviewerName   helpful  \\\n",
      "0  A210NOCSTBT4OD  0076144011       Sheila    [0, 0]   \n",
      "1  A28ILV4TOG8BH2  0130350591     ccjensen    [0, 0]   \n",
      "2  A31B4D7URW4DNZ  0307394530       3Gigi3  [11, 16]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  Have you ever thought about how you met your b...      4.0   \n",
      "1  The butter dish is serving us well, and keepin...      5.0   \n",
      "2  I anxiously waited for the book I had pre orde...      2.0   \n",
      "\n",
      "                                    summary  unixReviewTime   reviewTime  \n",
      "0                                    Lovely      1349308800   10 4, 2012  \n",
      "1  Nice looking, and keeps the butter fresh      1300752000  03 22, 2011  \n",
      "2                       Mother of the Bride      1214784000  06 30, 2008  \n"
     ]
    }
   ],
   "source": [
    "#Looking at a few exampls of the data.\n",
    "print('\\n Toys reviews summary')\n",
    "print(df_toys.shape)\n",
    "print(df_toys.columns)\n",
    "print(df_toys.head(3))\n",
    "print('\\n Video games reviews summary')\n",
    "print(df_vid.shape)\n",
    "print(df_vid.columns)\n",
    "print(df_vid.head(3))\n",
    "print('\\n Auto reviews summary')\n",
    "print(df_aut.shape)\n",
    "print(df_aut.columns)\n",
    "print(df_aut.head(3))\n",
    "print('\\n Home and Kitchen reviews summary')\n",
    "print(df_hnk.shape)\n",
    "print(df_hnk.columns)\n",
    "print(df_hnk.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings distribution for toys          reviewerID     asin  reviewerName  helpful  reviewText  summary  \\\n",
      "overall                                                                    \n",
      "1.0          192993   192993        192435   192993      192993   192993   \n",
      "2.0          115801   115801        115416   115801      115801   115801   \n",
      "3.0          193941   193941        193195   193941      193941   193941   \n",
      "4.0          407884   407884        406255   407884      407884   407884   \n",
      "5.0         1342152  1342152       1333623  1342152     1342152  1342152   \n",
      "\n",
      "         unixReviewTime  reviewTime  \n",
      "overall                              \n",
      "1.0              192993      192993  \n",
      "2.0              115801      115801  \n",
      "3.0              193941      193941  \n",
      "4.0              407884      407884  \n",
      "5.0             1342152     1342152  \n",
      "\n",
      " Ratings distribution for video games          reviewerID    asin  reviewerName  helpful  reviewText  summary  \\\n",
      "overall                                                                   \n",
      "1.0          152840  152840        149509   152840      152840   152840   \n",
      "2.0           77513   77513         76692    77513       77513    77513   \n",
      "3.0          124370  124370        122959   124370      124370   124370   \n",
      "4.0          260260  260260        256782   260260      260260   260260   \n",
      "5.0          709770  709770        692626   709770      709770   709770   \n",
      "\n",
      "         unixReviewTime  reviewTime  \n",
      "overall                              \n",
      "1.0              152840      152840  \n",
      "2.0               77513       77513  \n",
      "3.0              124370      124370  \n",
      "4.0              260260      260260  \n",
      "5.0              709770      709770  \n",
      "\n",
      " Ratings distribution for automobiles          reviewerID    asin  reviewerName  helpful  reviewText  summary  \\\n",
      "overall                                                                   \n",
      "1.0          122160  122160        121495   122160      122160   122160   \n",
      "2.0           64112   64112         63784    64112       64112    64112   \n",
      "3.0          103857  103857        103222   103857      103857   103857   \n",
      "4.0          230293  230293        228871   230293      230293   230293   \n",
      "5.0          853346  853346        847959   853346      853346   853346   \n",
      "\n",
      "         unixReviewTime  reviewTime  \n",
      "overall                              \n",
      "1.0              122160      122160  \n",
      "2.0               64112       64112  \n",
      "3.0              103857      103857  \n",
      "4.0              230293      230293  \n",
      "5.0              853346      853346  \n",
      "\n",
      " Ratings distribution for home and kitchen          reviewerID     asin  reviewerName  helpful  reviewText  summary  \\\n",
      "overall                                                                    \n",
      "1.0          418381   418381        416013   418381      418381   418381   \n",
      "2.0          242048   242048        240272   242048      242048   242048   \n",
      "3.0          345094   345094        342420   345094      345094   345094   \n",
      "4.0          740864   740864        734679   740864      740864   740864   \n",
      "5.0         2507539  2507539       2487340  2507539     2507539  2507539   \n",
      "\n",
      "         unixReviewTime  reviewTime  \n",
      "overall                              \n",
      "1.0              418381      418381  \n",
      "2.0              242048      242048  \n",
      "3.0              345094      345094  \n",
      "4.0              740864      740864  \n",
      "5.0             2507539     2507539  \n"
     ]
    }
   ],
   "source": [
    "#Count by ratings to determine skew in sample.\n",
    "print('Ratings distribution for toys',df_toys.groupby('overall').count())\n",
    "print('\\n Ratings distribution for video games',df_vid.groupby('overall').count())\n",
    "print('\\n Ratings distribution for automobiles',df_aut.groupby('overall').count())\n",
    "print('\\n Ratings distribution for home and kitchen',df_hnk.groupby('overall').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toys reviews examples\n",
      "\n",
      "AMEVO2LY6VEJA\n",
      "Great product, thank you! Our son loved the puzzles.  They have large pieces yet they are still challenging for a 4 year old.\n",
      "A3C9CSW3TJITGT\n",
      "I love these felt nursery rhyme characters and scenes.  The quality of the felt is good, and the illustrations are detailed and pretty.  As noted, the figures and scenes are printed on 2 large sheets of flannel and each individual item needs to be cut out.  This process took me 2 hours of tiny cutting.  To me it does not lend itself to a book form but rather laying out the scenes separately or for use on a flannel board.  However, I love the quiet play it offers for my toddler, and as a former Kindergarten teacher, I understand the value of learning rhyme and its connection to future reading.  Overall, delightful product with some work involved.\n",
      "A31POTIYCKSZ9G\n",
      "I see no directions for its use. Therefore I have to make up the games, unfortunately.\n",
      "\n",
      " Video games reviews examples\n",
      "\n",
      "AB9S9279OZ3QO\n",
      "I haven't gotten around to playing the campaign but the multiplayer is solid and pretty fun. Includes Zero Dark Thirty pack, an Online Pass, and the all powerful Battlefield 4 Beta access.\n",
      "A24SSUT5CSW8BH\n",
      "I want to start off by saying I have never played the Call of Duty games. This is only the second first person shooter game that I have own. I think it is a lot of fun. Has good graphics and nice story line. It does take some skill to get through the levels. I think all players can enjoy this game. There are three levels to choose from based on your skill level. If your looking for first person shooter game that has current military type play than this is a good buy.\n",
      "AK3V0HEBJMQ7J\n",
      "this will be my second medal of honor I love how the incorporate real life military stories in the game great\n",
      "\n",
      " Automobile reviews examples\n",
      "\n",
      "A108J5O7DG2WIM\n",
      "I loved the look and the great improvement at night drivingA bit expensive but work great.Installation took me about 3 hours.\n",
      "A1QBLUSZW281TA\n",
      "Put these on my 2011 can am outlander 800xt, easy to install, and being oem everything just plugged right in , even like the power switch they came with\n",
      "A3B40ZIZJ3HEP7\n",
      "Don't buy this item  , its not a 4 window roll up , its look nothing like the picture , they sent me some crap,  and the seller is charging me 20 % restocking fee plus I have to pay for shipping , I will never buy from them again , YOU HAVE BEEN WARNED ...\n",
      "\n",
      " Home and Kitchen reviews examples\n",
      "\n",
      "A210NOCSTBT4OD\n",
      "Have you ever thought about how you met your best friend? Was it normal, or was it wacky - like how Elias met Shohei? Pulling a boa constrictor snake named Mathilda out of your backpack can make a remarkable first impression! This book is about three best friends Elias, Honoria, and Shohei, who are united against \"That Which Is The Peshtigo School\". Their goal is to make it through the annual school science fair, but things don't always go as planned.Elias is part of a family made up of science fanatics who would do anything to win a science fair. Elias isn't exactly what you'd call the ambitious type, especially when it comes to science fairs. So he becomes like Galileo and \"retests\" one of his sibling's past projects. Honoria loves to be ambitious, especially when it comes to being a legal counsel extraordinaire. But when she faces a bigger challenge than beating Goliath Reed or getting a piranha to become vegetarian, she doesn't know if she can make it. Shohei is an all around slacker who tries to mooch off Elias instead of creating something on his own. His adoptive parents are constantly encouraging him to start \"hearing\" his ancestors. His mom has even turned Shohei's room into what looks like a walk-in Japanese museum exhibit!This book is laugh out loud hilarious and the more you read, the more exciting and unexpected it gets. I love the title on this book because it really made me laugh and want to read the book. I also like how people so different from one another can be such close friends. There is not much excitement in the beginning, but it builds up very quickly. So if you like that type of story, then this is the book for you.\n",
      "A28ILV4TOG8BH2\n",
      "The butter dish is serving us well, and keeping the butter fresh and healthy. Couldn't be happier with it, and the color is a pleasing green.\n",
      "A31B4D7URW4DNZ\n",
      "I anxiously waited for the book I had pre ordered.  Pics were beautiful, but...If you don't want a cake with fondant your pretty much out of luck. As most guests want something yummy to eat as well as pleasing to the eye, fondant just doesn't do it.  Sure it holds color better and makes a great presentation, it just isn't a pleaseing thing to eat.We did take away some ideas, we did use some fondant flowers on the lower layers (least likely to be eaten), and used butterccream for the really good and most enjoyed layers.Good Job Martha, maybe next time you could show how to make butter cream just as attractive as fondant.MOTB\n"
     ]
    }
   ],
   "source": [
    "#Looking at a few examples of review text\n",
    "print('Toys reviews examples\\n')\n",
    "for i in range(3):\n",
    "    print(df_toys['reviewerID'].iloc[i])\n",
    "    print(df_toys['reviewText'].iloc[i])\n",
    "\n",
    "print('\\n Video games reviews examples\\n')\n",
    "for i in range(3):\n",
    "    print(df_vid['reviewerID'].iloc[i])\n",
    "    print(df_vid['reviewText'].iloc[i])\n",
    "    \n",
    "print('\\n Automobile reviews examples\\n')\n",
    "for i in range(3):\n",
    "    print(df_aut['reviewerID'].iloc[i])\n",
    "    print(df_aut['reviewText'].iloc[i])\n",
    "    \n",
    "print('\\n Home and Kitchen reviews examples\\n')\n",
    "for i in range(3):\n",
    "    print(df_hnk['reviewerID'].iloc[i])\n",
    "    print(df_hnk['reviewText'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Summary metrics for Toy reviews\n",
      "Total \n",
      "\tCount of unique products: 327698 \n",
      "\tSum of their reviews 2252771\n",
      "Total with at least 5 reviews \n",
      "\tCount of unique products: 68782 Percentage of total 21%\n",
      "\tSum of their reviews 1775109 Percentage of total 79%\n",
      "Total with at least 20 reviews \n",
      "\tCount of unique products: 19992 Percentage of total 6%\n",
      "\tSum of their reviews 1275698 Percentage of total 57%\n",
      "\n",
      "Additional Summary metrics for Video Games reviews\n",
      "Total \n",
      "\tCount of unique products: 50210 \n",
      "\tSum of their reviews 1324753\n",
      "Total with at least 5 reviews \n",
      "\tCount of unique products: 23866 Percentage of total 48%\n",
      "\tSum of their reviews 1266698 Percentage of total 96%\n",
      "Total with at least 20 reviews \n",
      "\tCount of unique products: 10904 Percentage of total 22%\n",
      "\tSum of their reviews 1124236 Percentage of total 85%\n",
      "\n",
      "Additional Summary metrics for Auto reviews\n",
      "Total \n",
      "\tCount of unique products: 320112 \n",
      "\tSum of their reviews 1373768\n",
      "Total with at least 5 reviews \n",
      "\tCount of unique products: 42052 Percentage of total 13%\n",
      "\tSum of their reviews 912369 Percentage of total 66%\n",
      "Total with at least 20 reviews \n",
      "\tCount of unique products: 10218 Percentage of total 3%\n",
      "\tSum of their reviews 593687 Percentage of total 43%\n",
      "\n",
      "Additional Summary metrics for Home and Kitchen reviews\n",
      "Total \n",
      "\tCount of unique products: 410243 \n",
      "\tSum of their reviews 4253926\n",
      "Total with at least 5 reviews \n",
      "\tCount of unique products: 94181 Percentage of total 23%\n",
      "\tSum of their reviews 3688295 Percentage of total 87%\n",
      "Total with at least 20 reviews \n",
      "\tCount of unique products: 34140 Percentage of total 8%\n",
      "\tSum of their reviews 3061647 Percentage of total 72%\n"
     ]
    }
   ],
   "source": [
    "#Get the count by unique product id, and % of products and reviews left if we limit to products with at least X reviews\n",
    "def product_skew(df):\n",
    "    tempcnt = df.groupby('asin').size().reset_index()\n",
    "    cnt_total = tempcnt.count()[1]\n",
    "    sum_total = tempcnt.iloc[:,1].sum()\n",
    "    cnt_5 = tempcnt[tempcnt.iloc[:,1] > 5].count()[1]\n",
    "    sum_5 = tempcnt[tempcnt.iloc[:,1] > 5].sum()[1]\n",
    "    cnt_20 = tempcnt[tempcnt.iloc[:,1] > 20].count()[1]\n",
    "    sum_20 = tempcnt[tempcnt.iloc[:,1] > 20].sum()[1]\n",
    "    print('Total','\\n\\tCount of unique products:',cnt_total,'\\n\\tSum of their reviews',sum_total)\n",
    "    print('Total with at least 5 reviews','\\n\\tCount of unique products:',cnt_5,'Percentage of total {0:.0f}%'.format(cnt_5*100/cnt_total))\n",
    "    print('\\tSum of their reviews',sum_5,'Percentage of total {0:.0f}%'.format(sum_5*100/sum_total))\n",
    "    print('Total with at least 20 reviews','\\n\\tCount of unique products:',cnt_20,'Percentage of total {0:.0f}%'.format(cnt_20*100/cnt_total))\n",
    "    print('\\tSum of their reviews',sum_20,'Percentage of total {0:.0f}%'.format(sum_20*100/sum_total))\n",
    "    return\n",
    "\n",
    "print('Additional Summary metrics for Toy reviews')\n",
    "product_skew(df_toys)\n",
    "\n",
    "print('\\nAdditional Summary metrics for Video Games reviews')\n",
    "product_skew(df_vid)\n",
    "\n",
    "print('\\nAdditional Summary metrics for Auto reviews')\n",
    "product_skew(df_aut)\n",
    "\n",
    "print('\\nAdditional Summary metrics for Home and Kitchen reviews')\n",
    "product_skew(df_hnk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy reviews train, dev and test set dataframe shape: (1351662, 9) (450554, 9) (450555, 9)\n",
      "Video games reviews train, dev and test set dataframe shape: (794851, 9) (264951, 9) (264951, 9)\n",
      "Auto reviews train, dev and test set dataframe shape: (824260, 9) (274754, 9) (274754, 9)\n",
      "Home and Kitchen reviews train, dev and test set dataframe shape: (2552355, 9) (850785, 9) (850786, 9)\n"
     ]
    }
   ],
   "source": [
    "#Create train,dev,test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_toys,devtest = train_test_split(df_toys, test_size=0.4,random_state=42)\n",
    "dev_toys,test_toys = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Toy reviews train, dev and test set dataframe shape:',train_toys.shape,dev_toys.shape,test_toys.shape)\n",
    "\n",
    "#For Video games reviews\n",
    "train_vid,devtest = train_test_split(df_vid, test_size=0.4,random_state=42)\n",
    "dev_vid,test_vid = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Video games reviews train, dev and test set dataframe shape:',train_vid.shape,dev_vid.shape,test_vid.shape)\n",
    "\n",
    "#For Auto reviews\n",
    "train_aut,devtest = train_test_split(df_aut, test_size=0.4,random_state=42)\n",
    "dev_aut,test_aut = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Auto reviews train, dev and test set dataframe shape:',train_aut.shape,dev_aut.shape,test_aut.shape)\n",
    "\n",
    "#For Home and Kitchen reviews\n",
    "train_hnk,devtest = train_test_split(df_hnk, test_size=0.4,random_state=42)\n",
    "dev_hnk,test_hnk = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Home and Kitchen reviews train, dev and test set dataframe shape:',train_hnk.shape,dev_hnk.shape,test_hnk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create a smaller sized train and dev data set. Enables testing accuracy for different sizes.\n",
    "#Also binarizes the labels. Ratings of 1,2 set to 0; Ratings of 4,5 to 1.\n",
    "\n",
    "def set_df_size(size,data_train,data_dev):\n",
    "    size_train = size\n",
    "    len_max_train = data_train[data_train.overall!=3].shape[0] #max possible length of train data set taking out the 3 ratings.\n",
    "    #print(\"Number of reviews with ratings != 3 in train set\",len_max_train)\n",
    "    temp_size_train = min(len_max_train,size_train)\n",
    "\n",
    "    len_max_dev = data_dev[data_dev.overall!=3].shape[0]\n",
    "    #print(\"Number of reviews with ratings != 3 in dev set\",len_max_dev)\n",
    "    temp_size_dev = min(len_max_dev,int(0.3*temp_size_train)) #making the dev set about 0.3 times the train set.\n",
    "\n",
    "    temp_train_data = data_train[data_train.overall != 3][:temp_size_train]\n",
    "    #print('Size of train data',temp_train_data.shape)\n",
    "    #print(temp_train_data.groupby('overall').count())\n",
    "    #print(temp_train_toys[:5])\n",
    "\n",
    "    temp_dev_data = data_dev[data_dev.overall!=3][:temp_size_dev]\n",
    "    #print('Size of dev data',temp_dev_data.shape)\n",
    "    #print(temp_dev_data.groupby('overall').count())\n",
    "    #print(temp_dev_data[:2])\n",
    "    \n",
    "    #Binarize ratings\n",
    "    temp_train_y = np.zeros(temp_size_train)\n",
    "    temp_train_y[temp_train_data.overall > 3] = 1\n",
    "    temp_dev_y = np.zeros(temp_size_dev)\n",
    "    temp_dev_y[temp_dev_data.overall>3] = 1\n",
    "    #print('binarized y shape',temp_train_y.shape,temp_dev_y.shape)\n",
    "    #print(temp_dev_y[:20],data_dev.overall[:20])\n",
    "    return temp_train_data,temp_dev_data,temp_train_y,temp_dev_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_df = ['toys','vid','aut','hnk'] #list of keys that refer to each dataframe. Adding a new dataframe would require updating this list\n",
    "dict_train_df = {} #Dict to store train input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_dev_df = {} #Dict to store dev input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_train_y = {} #Dict to store binarized train data label for each domain\n",
    "dict_dev_y = {} #Dict to store binarized dev data label for each domain\n",
    "#print(len(dict_train_df))\n",
    "\n",
    "def create_sized_data(size = 100000):\n",
    "    size_train = size #Set size of train set here. This is a hyperparameter.\n",
    "    key = list_df[0]\n",
    "    #print('Toys reviews\\n')\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_toys,dev_toys)\n",
    "    #print('\\n Video games reviews\\n')\n",
    "    key = list_df[1]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_vid,dev_vid)\n",
    "    #print('\\n Auto reviews\\n')\n",
    "    key = list_df[2]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_aut,dev_aut)\n",
    "    #print('\\n Home and Kitchen reviews\\n')\n",
    "    key = list_df[3]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_hnk,dev_hnk)\n",
    "    \n",
    "create_sized_data()\n",
    "#print(len(dict_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number words in training corpus for toys 31005\n",
      "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.89%\n",
      "Number words in training corpus for vid 44569\n",
      "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.62%\n",
      "Number words in training corpus for aut 27220\n",
      "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.26%\n",
      "Number words in training corpus for hnk 27825\n",
      "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 90.95%\n",
      "Classification report for toys \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.75      0.73      4465\n",
      "        1.0       0.96      0.95      0.95     25535\n",
      "\n",
      "avg / total       0.92      0.92      0.92     30000\n",
      "\n",
      "Classification report for vid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.71      0.70      5642\n",
      "        1.0       0.93      0.93      0.93     24358\n",
      "\n",
      "avg / total       0.89      0.89      0.89     30000\n",
      "\n",
      "Classification report for aut \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.64      0.68      4329\n",
      "        1.0       0.94      0.96      0.95     25671\n",
      "\n",
      "avg / total       0.91      0.91      0.91     30000\n",
      "\n",
      "Classification report for hnk \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.70      0.73      5087\n",
      "        1.0       0.94      0.95      0.95     24913\n",
      "\n",
      "avg / total       0.91      0.91      0.91     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting reviews to sparse matrix of word ids with count vectorizer, and using Naive Bayes to make the prediction.\n",
    "#This section also creates the count_vectorizer and Naive Bayes models for each domain to be used to test transfer learning\n",
    "dict_vectorizers = {} #Dict to store the count_vectorizer model developed on each domain\n",
    "dict_train_ids = {} #Dict to store train data reviews as sparse matrix of word ids\n",
    "dict_dev_ids = {} #Dict to store dev data reviews as sparse matrix of word ids\n",
    "dict_nb = {} #Dict to store naive bayes model developed on each domain. Assumes input features are developed using the corresponding count_vectorizer\n",
    "dict_dev_ypred = {} #Dict to store dev predictions\n",
    "\n",
    "def create_base_NB_models():\n",
    "    for key in list_df:\n",
    "        #Converting ratings to tokenized word id counts as a sparse matrix using count_vectorizer\n",
    "        dict_vectorizers[key] = CountVectorizer(min_df=2, stop_words='english')\n",
    "        dict_train_ids[key] = dict_vectorizers[key].fit_transform(dict_train_df[key].reviewText)\n",
    "        dict_dev_ids[key] = dict_vectorizers[key].transform(dict_dev_df[key].reviewText)\n",
    "        print(\"Number words in training corpus for\",key,len(dict_vectorizers[key].get_feature_names()))\n",
    "        #print(key,'dataset id shapes',dict_train_ids[key].shape, dict_dev_ids[key].shape)\n",
    "\n",
    "        #Building a Naive Bayes model to predict the ratings\n",
    "        dict_nb[key] = MultinomialNB()\n",
    "        dict_nb[key].fit(dict_train_ids[key],dict_train_y[key])\n",
    "        dict_dev_ypred[key] = dict_nb[key].predict(dict_dev_ids[key])\n",
    "        acc = accuracy_score(dict_dev_y[key], dict_dev_ypred[key])\n",
    "        print(\"Accuracy on\",key,\"dev set for binary prediction with toys naive bayes model: {:.02%}\".format(acc))\n",
    "\n",
    "def print_base_NB_details():\n",
    "    for key in list_df:\n",
    "      print('Classification report for',key,'\\n',classification_report(dict_dev_y[key], dict_dev_ypred[key]))  \n",
    "        \n",
    "create_base_NB_models()\n",
    "print_base_NB_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 91.9% 90.9% 90.3% 90.9%\n",
      "vid  86.4% 88.6% 87.1% 86.9%\n",
      "aut  74.6% 78.4% 91.3% 82.2%\n",
      "hnk  84.0% 84.6% 90.5% 90.9%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of transfer learning\n",
    "\n",
    "dict_transfer_ids = {} #Dictionary to store the dev vector ids for dataframe A(df) using the count_vectorizer of dataframe B(vect)\n",
    "transfer_results = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store accuracy on transfer. Col = Model, row = dataframe\n",
    "\n",
    "def estimate_transfer_accuracy():\n",
    "    for vectKey in list_df:\n",
    "        dict_transfer_ids[vectKey] = {}\n",
    "        #print('vectKey',vectKey)\n",
    "        for dfKey in list_df:\n",
    "            #print('dfKey',dfKey)\n",
    "            dict_transfer_ids[vectKey][dfKey] = dict_vectorizers[vectKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "            #print(dfKey,'dataset using ',vectKey,' count vectorizer, id shapes',dict_transfer_ids[vectKey][dfKey].shape)\n",
    "            dict_dev_ypred = dict_nb[vectKey].predict(dict_transfer_ids[vectKey][dfKey])\n",
    "            acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "            #print(\"Accuracy on \",dfKey,\" dev set for binary prediction with \", vectKey,\" naive bayes model: {:.02%}\".format(acc))\n",
    "            transfer_results[vectKey][dfKey] = acc\n",
    "\n",
    "    print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "    print(\"Accuracy of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results.to_string(float_format = '{:.01%}'.format))\n",
    "\n",
    "estimate_transfer_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined df shape for toys vid (200000,)\n",
      "Number words in training corpus for keys toys vid 56195\n",
      "combined df shape for toys aut (200000,)\n",
      "Number words in training corpus for keys toys aut 43529\n",
      "combined df shape for toys hnk (200000,)\n",
      "Number words in training corpus for keys toys hnk 43129\n",
      "combined df shape for vid aut (200000,)\n",
      "Number words in training corpus for keys vid aut 55983\n",
      "combined df shape for vid hnk (200000,)\n",
      "Number words in training corpus for keys vid hnk 55831\n",
      "combined df shape for aut hnk (200000,)\n",
      "Number words in training corpus for keys aut hnk 40614\n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys   NaN 90.1% 87.5% 89.2%\n",
      "vid  86.0%   NaN 81.1% 82.6%\n",
      "aut  71.6% 74.0%   NaN 78.7%\n",
      "hnk  81.5% 79.6% 88.4%   NaN\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of transfer learning - updating to use countvectorizer developed on both dataframes instead of just the source domain.\n",
    "\n",
    "dict_transfer_vect = {} ##Dictionary to store countvectorizer for two dfs combined.\n",
    "dict_transfer_train_ids = {} ##Dictionary to store train ids using countvectorizer for two dfs combined.\n",
    "dict_transfer_dev_ids = {} ## Dictionary to store dev ids using countvectorizer for two dfs combined.\n",
    "transfer_results = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store accuracy on transfer. Col = Model, row = dataframe\n",
    "\n",
    "for vectKey in list_df:\n",
    "    dict_transfer_vect[vectKey] = {}\n",
    "    dict_transfer_train_ids[vectKey] = {}\n",
    "    dict_transfer_dev_ids[vectKey] = {}\n",
    "\n",
    "def estimate_transfer_accuracy():\n",
    "    #First create the countvectorizer for the two dfs together, then create the train and dev ids for both dfs using that.\n",
    "    for vectKey in list_df:\n",
    "        #print('vectKey',vectKey)\n",
    "        for dfKey in list_df:\n",
    "            if list_df.index(dfKey) > list_df.index(vectKey): \n",
    "                \n",
    "                #Create combined dataframe of reviewText from both domains\n",
    "                temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,dict_train_df[dfKey].reviewText])\n",
    "                print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape)\n",
    "                \n",
    "                #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "                dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "                dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "                print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "                #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "                dict_transfer_train_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_train_df[vectKey].reviewText)\n",
    "                dict_transfer_train_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_train_df[dfKey].reviewText)\n",
    "                dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "                dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "                #using vectKey as source, and dfkey as target\n",
    "                source_modelVect = MultinomialNB()\n",
    "                source_modelVect.fit(dict_transfer_train_ids[vectKey][dfKey],dict_train_y[vectKey])\n",
    "                dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "                acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "                transfer_results[vectKey][dfKey] = acc\n",
    "                \n",
    "                #using dfKey as source, and Vectkey as target\n",
    "                source_modeldf = MultinomialNB()\n",
    "                source_modeldf.fit(dict_transfer_train_ids[dfKey][vectKey],dict_train_y[dfKey])\n",
    "                dict_dev_ypred = source_modeldf.predict(dict_transfer_dev_ids[vectKey][dfKey])\n",
    "                acc = accuracy_score(dict_dev_y[vectKey], dict_dev_ypred)\n",
    "                #print(\"Accuracy on \",dfKey,\" dev set for binary prediction with \", vectKey,\" naive bayes model: {:.02%}\".format(acc))\n",
    "                transfer_results[dfKey][vectKey] = acc\n",
    "\n",
    "    print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "    print(\"Accuracy of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results.to_string(float_format = '{:.01%}'.format))\n",
    "\n",
    "estimate_transfer_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer loss on rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid  aut   hnk\n",
      "toys  0.0%  1.6% 3.0%  2.1%\n",
      "vid   3.5%  0.0% 6.3%  5.8%\n",
      "aut  22.7% 19.8% 0.0% 12.3%\n",
      "hnk  11.4% 12.1% 1.9%  0.0%\n"
     ]
    }
   ],
   "source": [
    "#Calculating and displaying as transfer loss\n",
    "transfer_loss = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store loss in accuracy on transfer. Col = Model, row = dataframe\n",
    "def estimate_transfer_loss():\n",
    "    for A in list_df:\n",
    "        for B in list_df:\n",
    "            transfer_loss[A][B] = transfer_results[B][B] - transfer_results[A][B]\n",
    "    print(\"Transfer loss on rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_loss.to_string(float_format = '{:.01%}'.format))\n",
    "\n",
    "estimate_transfer_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train data_set size = 5000\n",
      "Number words in training corpus for toys 7133\n",
      "Accuracy on toys dev set for binary prediction with toys naive bayes model: 90.53%\n",
      "Number words in training corpus for vid 10570\n",
      "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.87%\n",
      "Number words in training corpus for aut 6610\n",
      "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.40%\n",
      "Number words in training corpus for hnk 7255\n",
      "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 89.80%\n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 90.5% 88.1% 89.9% 90.0%\n",
      "vid  86.1% 88.9% 86.1% 86.4%\n",
      "aut  78.5% 82.5% 91.4% 88.8%\n",
      "hnk  86.0% 87.4% 88.5% 89.8%\n",
      "Transfer loss on rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys  vid  aut  hnk\n",
      "toys  0.0% 2.5% 0.7% 0.5%\n",
      "vid   2.7% 0.0% 2.8% 2.5%\n",
      "aut  12.9% 8.9% 0.0% 2.6%\n",
      "hnk   3.8% 2.4% 1.3% 0.0%\n",
      "\n",
      " Train data_set size = 100000\n",
      "Number words in training corpus for toys 31452\n",
      "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.55%\n",
      "Number words in training corpus for vid 44827\n",
      "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.65%\n",
      "Number words in training corpus for aut 27765\n",
      "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.41%\n",
      "Number words in training corpus for hnk 28189\n",
      "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.27%\n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 91.5% 91.2% 91.6% 91.2%\n",
      "vid  85.8% 88.6% 87.7% 87.3%\n",
      "aut  71.6% 76.1% 91.4% 82.0%\n",
      "hnk  83.2% 85.3% 91.1% 91.3%\n",
      "Transfer loss on rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut  hnk\n",
      "toys  0.0%  0.4% -0.1% 0.3%\n",
      "vid   2.9%  0.0%  0.9% 1.4%\n",
      "aut  19.8% 15.3%  0.0% 9.4%\n",
      "hnk   8.1%  6.0%  0.2% 0.0%\n"
     ]
    }
   ],
   "source": [
    "#for size in (50000,100000,250000,500000,1000000):\n",
    "for size in (5000,100000):\n",
    "    print(\"\\n Train data_set size =\",size)\n",
    "    create_sized_data(size = size)\n",
    "    create_base_NB_models()\n",
    "    estimate_transfer_accuracy()\n",
    "    estimate_transfer_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function to calculate JS Divergence using two discrete distributions.\n",
    "from scipy.stats import entropy\n",
    "from scipy import spatial\n",
    "#from scipy.sparse.linalg import norm\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def JSD(P, Q):\n",
    "   _P = P / norm(P, ord=1)\n",
    "   _Q = Q / norm(Q, ord=1)\n",
    "   _M = 0.5 * (_P + _Q)\n",
    "   return 0.5 * (entropy(_P, _M) + entropy(_Q, _M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 9)\n",
      "Number words in training corpus 41262\n",
      "toys (100000, 41262)\n",
      "vid (100000, 41262)\n",
      "aut (100000, 41262)\n",
      "hnk (100000, 41262)\n"
     ]
    }
   ],
   "source": [
    "#Create a vocabulary on the reviewText of all dataframes for the sake of comparing their distributions on the same baseline.\n",
    "all_df_reviews = pd.DataFrame(columns = dict_train_df[list_df[0]].columns)\n",
    "for key in list_df:\n",
    "    #print(dict_train_df[key].shape)\n",
    "    all_df_reviews = pd.concat([dict_train_df[key],all_df_reviews])\n",
    "print(all_df_reviews.shape)\n",
    "#print(type(all_df_reviews))\n",
    "#print(all_df_reviews.columns)\n",
    "\n",
    "all_vectorizer = CountVectorizer(min_df=5, max_df=0.8, stop_words='english')\n",
    "all_ids = all_vectorizer.fit_transform(all_df_reviews.reviewText)\n",
    "print(\"Number words in training corpus\",len(all_vectorizer.get_feature_names()))\n",
    "\n",
    "#Create a word if distribution of each df on the integrated vocabulary ids.\n",
    "dict_allVocab_ids = {}\n",
    "for key in list_df:\n",
    "    dict_allVocab_ids[key] = all_vectorizer.transform(dict_train_df[key].reviewText)\n",
    "    print(key,dict_allVocab_ids[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Divergence\n",
      "                  toys               vid               aut               hnk\n",
      "toys             [0.0]  [0.121900206869]  [0.149253766723]  [0.129181255531]\n",
      "vid   [0.121900206869]             [0.0]  [0.197747372379]  [0.200978538535]\n",
      "aut   [0.149253766723]  [0.197747372379]             [0.0]  [0.118183647432]\n",
      "hnk   [0.129181255531]  [0.200978538535]  [0.118183647432]             [0.0]\n",
      "\n",
      "Cosine Distance\n",
      "          toys       vid          aut          hnk\n",
      "toys         0  0.345511     0.287423     0.236629\n",
      "vid   0.345511         0     0.547328     0.526993\n",
      "aut   0.287423  0.547328  2.22045e-16     0.144065\n",
      "hnk   0.236629  0.526993     0.144065 -2.22045e-16\n"
     ]
    }
   ],
   "source": [
    "JSD_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "cosine_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "for key1 in list_df:\n",
    "   for key2 in list_df:\n",
    "       dict_train_ids_1 = dict_allVocab_ids[key1].sum(axis=0).T\n",
    "       dict_train_ids_2 = dict_allVocab_ids[key2].sum(axis=0).T\n",
    "       #print(dict_allVocab_ids[key1].shape,dict_train_ids_1.shape,dict_train_ids_2.shape)\n",
    "       JSD_results[key1][key2] = JSD(dict_train_ids_1,dict_train_ids_2)\n",
    "       cosine_results[key1][key2] = spatial.distance.cosine(dict_train_ids_1,dict_train_ids_2)\n",
    "       \n",
    "print('JS Divergence')\n",
    "print(JSD_results)\n",
    "print('\\nCosine Distance')\n",
    "print(cosine_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Divergence\n",
      "                  toys               vid               aut               hnk\n",
      "toys               NaN  [0.128890147874]  [0.153422214856]  [0.132789423959]\n",
      "vid   [0.126816613629]               NaN  [0.202562442184]  [0.205457618486]\n",
      "aut   [0.154323392071]  [0.203572077456]               NaN  [0.122984089333]\n",
      "hnk   [0.134259265546]  [0.207322916085]  [0.122498015676]               NaN\n",
      "\n",
      "Cosine Distance\n",
      "          toys       vid       aut       hnk\n",
      "toys       NaN  0.348899  0.285166  0.232095\n",
      "vid    0.34513       NaN  0.547097  0.526382\n",
      "aut   0.289583  0.548537       NaN  0.145872\n",
      "hnk   0.236801  0.526535  0.143537       NaN\n"
     ]
    }
   ],
   "source": [
    "#Calculating similarity using countVectorizer of two dfs together rather than all 4.\n",
    "JSD_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "cosine_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "for key1 in list_df:\n",
    "    for key2 in list_df:\n",
    "        if list_df.index(key1)!= list_df.index(key2):\n",
    "            #print(key1,key2)\n",
    "            dict_train_ids_1 = dict_transfer_train_ids[key1][key2].sum(axis=0).T\n",
    "            dict_dev_ids_2 = dict_transfer_dev_ids[key2][key1].sum(axis=0).T\n",
    "            #print(dict_allVocab_ids[key1].shape,dict_train_ids_1.shape,dict_train_ids_2.shape)\n",
    "            JSD_results[key1][key2] = JSD(dict_train_ids_1,dict_dev_ids_2)\n",
    "            cosine_results[key1][key2] = spatial.distance.cosine(dict_train_ids_1,dict_dev_ids_2)\n",
    "       \n",
    "print('JS Divergence')\n",
    "print(JSD_results)\n",
    "print('\\nCosine Distance')\n",
    "print(cosine_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43529, 1) (100000,) (30000,)\n",
      "111165.904643\n",
      "1.0 0.592696517226 (100000,)\n",
      "number of reviews with zero norm =  41\n",
      "2 (array([    2,     9,    21,    64,   194,   455,   857,  1661,  2772,\n",
      "        4521,  6692,  8950, 11210, 12703, 13418, 12543, 10782,  7831,\n",
      "        4189,  1126]), array([ 0.59269652,  0.61306169,  0.63342687,  0.65379204,  0.67415721,\n",
      "        0.69452239,  0.71488756,  0.73525274,  0.75561791,  0.77598308,\n",
      "        0.79634826,  0.81671343,  0.83707861,  0.85744378,  0.87780896,\n",
      "        0.89817413,  0.9185393 ,  0.93890448,  0.95926965,  0.97963483,  1.        ]))\n",
      "1.0 0.605343760681\n"
     ]
    }
   ],
   "source": [
    "#calculating cosine similarity for each individual review.\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "key1 = 'toys'\n",
    "key2 = 'aut'\n",
    "source_ids = dict_transfer_train_ids[key1][key2].sum(axis=0).T\n",
    "cosine_distance_train = np.ones((len(dict_train_y[key2])))\n",
    "cosine_distance_dev = np.ones((len(dict_dev_y[key2])))\n",
    "print(source_ids.shape,cosine_distance_train.shape,cosine_distance_dev.shape)\n",
    "print(norm(source_ids))\n",
    "n = norm(source_ids)\n",
    "\n",
    "count_zero_norm = 0\n",
    "for i in range(len(dict_train_y[key2])):\n",
    "    y = dict_transfer_train_ids[key2][key1][i].T.toarray()\n",
    "    if norm(y) == 0:\n",
    "        cosine_distance_train[i] = 1\n",
    "        count_zero_norm += 1\n",
    "    else:\n",
    "        cosine_distance_train[i] = spatial.distance.cosine(source_ids,y)\n",
    "print(max(cosine_distance_train),min(cosine_distance_train),cosine_distance_train.shape)\n",
    "print('number of reviews with zero norm = ',count_zero_norm)\n",
    "\n",
    "y = np.histogram(cosine_distance_train,bins=20, normed=False)\n",
    "print(len(y),y)\n",
    "\n",
    "for i in range(len(dict_dev_y[key2])):\n",
    "    z = dict_transfer_dev_ids[key2][key1][i].T.toarray()\n",
    "    if norm(z) == 0:\n",
    "        cosine_distance_dev[i] = 1\n",
    "    else:\n",
    "        cosine_distance_dev[i] = spatial.distance.cosine(source_ids,z)\n",
    "        \n",
    "print(max(cosine_distance_dev),min(cosine_distance_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.histogram(cosine_distance_train,bins=20, normed=False)\n",
    "print(len(y),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall transfer accuracy 0.7159\n",
      "Overall AUC 0.846190231547\n",
      "Buckets of cosine distance 0.0 to 0.1, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.1 to 0.1, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.1 to 0.2, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.2 to 0.2, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.2 to 0.2, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.2 to 0.3, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.3 to 0.4, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.4 to 0.4, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.4 to 0.5, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.5 to 0.5, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.5 to 0.6, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.6 to 0.6, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
      "Buckets of cosine distance 0.6 to 0.7, transfer accuracy: 1.00 auc 0.0 # reviews 7 % pos 1.0\n",
      "Buckets of cosine distance 0.7 to 0.7, transfer accuracy: 0.89 auc 0.953795379538 # reviews 104 % pos 0.971153846154\n",
      "Buckets of cosine distance 0.7 to 0.8, transfer accuracy: 0.84 auc 0.881494057725 # reviews 658 % pos 0.942249240122\n",
      "Buckets of cosine distance 0.8 to 0.8, transfer accuracy: 0.79 auc 0.880781530086 # reviews 2622 % pos 0.944317315027\n",
      "Buckets of cosine distance 0.8 to 0.9, transfer accuracy: 0.75 auc 0.8715027992 # reviews 6462 % pos 0.900185701021\n",
      "Buckets of cosine distance 0.9 to 0.9, transfer accuracy: 0.70 auc 0.851023751584 # reviews 9729 % pos 0.855586391202\n",
      "Buckets of cosine distance 0.9 to 1.0, transfer accuracy: 0.68 auc 0.826283949494 # reviews 7900 % pos 0.805189873418\n",
      "Buckets of cosine distance 1.0 to 1.0, transfer accuracy: 0.68 auc 0.802225737415 # reviews 2504 % pos 0.7803514377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:1110: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy by distance buckets\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "source_modelVect = MultinomialNB()\n",
    "source_modelVect.fit(dict_transfer_train_ids[key1][key2],dict_train_y[key1])\n",
    "dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[key2][key1])\n",
    "dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[key2][key1])[:,1]\n",
    "#print(dict_dev_ypred_proba[:5])\n",
    "dev_y_actual = dict_dev_y[key2]\n",
    "#print(dict_dev_ypred[:5])\n",
    "acc = accuracy_score(dict_dev_y[key2], dict_dev_ypred)\n",
    "print('Overall transfer accuracy',acc)\n",
    "auc = roc_auc_score(dict_dev_y[key2], dict_dev_ypred_proba, average = 'weighted')\n",
    "print('Overall AUC',auc)\n",
    "\n",
    "acc_by_similarity = np.zeros((20))\n",
    "auc_by_sim = np.zeros((20))\n",
    "percent_pos_class = np.zeros((20))\n",
    "span = 0.05\n",
    "\n",
    "for i in range(20):\n",
    "    acc_by_similarity[i] = accuracy_score(dev_y_actual[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))], \n",
    "                                          dict_dev_ypred[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))])\n",
    "    dev_y_selected = dev_y_actual[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))]\n",
    "    percent_pos_class[i] = np.sum(dev_y_selected)/len(dev_y_selected)\n",
    "    if percent_pos_class[i] < 0.99:\n",
    "        auc_by_sim[i] = roc_auc_score(dev_y_actual[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))], \n",
    "                                    dict_dev_ypred_proba[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))],\n",
    "                                     average = 'weighted')\n",
    "    percent_pos_class[i] = np.sum(dev_y_selected)/len(dev_y_selected)\n",
    "    print('Buckets of cosine distance %0.1f to %0.1f, transfer accuracy: %0.2f'%(span*(i),span*(i+1),\n",
    "            acc_by_similarity[i]),'auc',auc_by_sim[i],'# reviews',len(dev_y_selected), '% pos',percent_pos_class[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined df shape for toys aut (100000,) (100000,)\n",
      "Number words in training corpus for keys toys aut 31005\n",
      "for size = 0, accuracy = 0.746\n",
      "combined df shape for toys aut (105000,) (105000,)\n",
      "Number words in training corpus for keys toys aut 32140\n",
      "for size = 5000, accuracy = 0.793\n",
      "combined df shape for toys aut (110000,) (110000,)\n",
      "Number words in training corpus for keys toys aut 33106\n",
      "for size = 10000, accuracy = 0.819\n",
      "combined df shape for toys aut (125000,) (125000,)\n",
      "Number words in training corpus for keys toys aut 35295\n",
      "for size = 25000, accuracy = 0.856\n",
      "combined df shape for toys aut (140000,) (140000,)\n",
      "Number words in training corpus for keys toys aut 37254\n",
      "for size = 40000, accuracy = 0.874\n",
      "combined df shape for toys aut (170000,) (170000,)\n",
      "Number words in training corpus for keys toys aut 40549\n",
      "for size = 70000, accuracy = 0.890\n",
      "combined df shape for toys aut (200000,) (200000,)\n",
      "Number words in training corpus for keys toys aut 43529\n",
      "for size = 100000, accuracy = 0.897\n"
     ]
    }
   ],
   "source": [
    " #Improvement in accuracy with adding increasing random sample from the target domain to the source domain\n",
    "    \n",
    "vectKey = 'toys'\n",
    "dfKey = 'aut'\n",
    "size_list = [0,5000,10000,25000,40000,70000,100000]\n",
    "\n",
    "for size in size_list: \n",
    "    \n",
    "    #pick out samples from target domain\n",
    "    df_to_add = dict_train_df[dfKey][:size]\n",
    "    labels_to_add = dict_train_y[dfKey][:size]\n",
    "    \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,df_to_add.reviewText])\n",
    "    temp_two_labels = np.concatenate([dict_train_y[vectKey],labels_to_add])\n",
    "    print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape, temp_two_labels.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "    dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train = dict_transfer_vect[vectKey][dfKey].transform(temp_two_df_reviews)\n",
    "    dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "    dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "    #using vectKey as source, and dfkey as target\n",
    "    source_modelVect = MultinomialNB()\n",
    "    source_modelVect.fit(dict_transfer_train,temp_two_labels)\n",
    "    dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "    acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "    print('for size = %d, accuracy = %0.3f'%(size,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 8 6]\n",
      "pre sort df              reviewerID        asin                             reviewerName  \\\n",
      "496617   A3KLNIO5LSJUFX  B001BQISSS                                zephyrous   \n",
      "1200153   A5AMO3KTY3QQR  B008OEQ6WU  M. Chase \"Film,Theatre, Products Used.\"   \n",
      "409816   A3UXW18DP4WSD6  B000VZJH6W                        Richard \"Richard\"   \n",
      "886302   A1GSIW3K44CAWW  B004DRV5GY                                jeffs4589   \n",
      "\n",
      "        helpful                                         reviewText  overall  \\\n",
      "496617   [0, 0]  This ashtray looks smaller in person than it d...      4.0   \n",
      "1200153  [1, 1]  Easy to install this air filter does what it s...      5.0   \n",
      "409816   [0, 0]  I need to check to price at the auto stores to...      5.0   \n",
      "886302   [0, 0]  THE OLD LIGHTS WERE FOGGED OVER WITH THE NEW O...      5.0   \n",
      "\n",
      "                     summary  unixReviewTime   reviewTime  \n",
      "496617     Simple and cheap.      1398988800   05 2, 2014  \n",
      "1200153           Air Filter      1370217600   06 3, 2013  \n",
      "409816         great to have      1393718400   03 2, 2014  \n",
      "886302   GREAT FOR THE PRICE      1373414400  07 10, 2013  \n",
      "sort indices [1 0 3 2]\n",
      "sorted array [2 4 6 8]\n",
      "sorted dataframe              reviewerID        asin                             reviewerName  \\\n",
      "1200153   A5AMO3KTY3QQR  B008OEQ6WU  M. Chase \"Film,Theatre, Products Used.\"   \n",
      "496617   A3KLNIO5LSJUFX  B001BQISSS                                zephyrous   \n",
      "886302   A1GSIW3K44CAWW  B004DRV5GY                                jeffs4589   \n",
      "409816   A3UXW18DP4WSD6  B000VZJH6W                        Richard \"Richard\"   \n",
      "\n",
      "        helpful                                         reviewText  overall  \\\n",
      "1200153  [1, 1]  Easy to install this air filter does what it s...      5.0   \n",
      "496617   [0, 0]  This ashtray looks smaller in person than it d...      4.0   \n",
      "886302   [0, 0]  THE OLD LIGHTS WERE FOGGED OVER WITH THE NEW O...      5.0   \n",
      "409816   [0, 0]  I need to check to price at the auto stores to...      5.0   \n",
      "\n",
      "                     summary  unixReviewTime   reviewTime  \n",
      "1200153           Air Filter      1370217600   06 3, 2013  \n",
      "496617     Simple and cheap.      1398988800   05 2, 2014  \n",
      "886302   GREAT FOR THE PRICE      1373414400  07 10, 2013  \n",
      "409816         great to have      1393718400   03 2, 2014  \n",
      "last obs             reviewerID        asin       reviewerName helpful  \\\n",
      "886302  A1GSIW3K44CAWW  B004DRV5GY          jeffs4589  [0, 0]   \n",
      "409816  A3UXW18DP4WSD6  B000VZJH6W  Richard \"Richard\"  [0, 0]   \n",
      "\n",
      "                                               reviewText  overall  \\\n",
      "886302  THE OLD LIGHTS WERE FOGGED OVER WITH THE NEW O...      5.0   \n",
      "409816  I need to check to price at the auto stores to...      5.0   \n",
      "\n",
      "                    summary  unixReviewTime   reviewTime  \n",
      "886302  GREAT FOR THE PRICE      1373414400  07 10, 2013  \n",
      "409816        great to have      1393718400   03 2, 2014  \n"
     ]
    }
   ],
   "source": [
    "# temp code to figure and confirm sorting of arrays and dataframes\n",
    "arr1 = np.array([2,1,4,3])\n",
    "arr2 = np.array([4,2,8,6])\n",
    "print(arr2)\n",
    "df = dict_train_df['aut'][:4]\n",
    "print('pre sort df',df)\n",
    "sort_id = np.argsort(arr1)\n",
    "print('sort indices',sort_id)\n",
    "arr2 = arr2[sort_id]\n",
    "print('sorted array',arr2)\n",
    "df = df.iloc([sort_id])\n",
    "df1 = df[sort_id]\n",
    "#print(df[sort_id])\n",
    "print('sorted dataframe',df1)\n",
    "print('last obs',df1[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83897 87459  6515 ..., 68601  2674 88133]\n",
      "pre sort 496971    What a beautiful jacket, excellant quality , u...\n",
      "154362    Fel Pro OEM quality at rock-bottom price deliv...\n",
      "781005    I wasn't sure how well these wipes would clean...\n",
      "877282    I bought a pair of aftermarket HID headlights ...\n",
      "542143    Nice, but I misread and thought they were for ...\n",
      "Name: reviewText, dtype: object [ 1.  1.  1.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.\n",
      "  1.  1.]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      " Post sort 1066682                   gooooood\n",
      "679235         Its all about the U\n",
      "835032                            \n",
      "749000     This is not an ashtray.\n",
      "737700                            \n",
      "Name: reviewText, dtype: object [ 1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  0.  1.] first 20 [ 0.59269652  0.6059804   0.61797067  0.62121062  0.6236347   0.62776251\n",
      "  0.62796823  0.6283241   0.62888674  0.62991426  0.63153037  0.63427282\n",
      "  0.63466891  0.64026683  0.64058714  0.64162127  0.64213629  0.64387865\n",
      "  0.6443244   0.64447924] [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "combined df shape for toys aut (105000,) (105000,)\n",
      "Number words in training corpus for keys toys aut 32056\n",
      "for size = 5000, accuracy = 0.834\n",
      "combined df shape for toys aut (110000,) (110000,)\n",
      "Number words in training corpus for keys toys aut 33037\n",
      "for size = 10000, accuracy = 0.863\n",
      "combined df shape for toys aut (125000,) (125000,)\n",
      "Number words in training corpus for keys toys aut 35398\n",
      "for size = 25000, accuracy = 0.886\n",
      "combined df shape for toys aut (140000,) (140000,)\n",
      "Number words in training corpus for keys toys aut 37414\n",
      "for size = 40000, accuracy = 0.892\n",
      "combined df shape for toys aut (170000,) (170000,)\n",
      "Number words in training corpus for keys toys aut 40787\n",
      "for size = 70000, accuracy = 0.896\n",
      "combined df shape for toys aut (200000,) (200000,)\n",
      "Number words in training corpus for keys toys aut 43529\n",
      "for size = 100000, accuracy = 0.897\n"
     ]
    }
   ],
   "source": [
    " #Improvement in accuracy with adding an actively selected sample of different sizes from the target domain to the source domain\n",
    "    \n",
    "vectKey = 'toys'\n",
    "dfKey = 'aut'\n",
    "size_list = [5000,10000,25000,40000,70000,100000]\n",
    "\n",
    "sort_ids = np.argsort(cosine_distance_train)\n",
    "cosine_distance_sorted = cosine_distance_train[sort_ids]\n",
    "print(sort_ids)\n",
    "df_target_ids_pre = dict_train_df[dfKey]\n",
    "df_target_labels_pre = dict_train_y[dfKey]\n",
    "print('pre sort',df_target_ids_pre.reviewText[-5:],df_target_labels_pre[-20:])\n",
    "print(type(df_target_labels_pre))\n",
    "df_target_ids_pre = df_target_ids_pre.iloc([sort_ids])\n",
    "df_target_ids = df_target_ids_pre[sort_ids]\n",
    "df_target_labels = df_target_labels_pre[sort_ids]\n",
    "print('\\n Post sort',df_target_ids.reviewText[-5:],df_target_labels[-20:],'first 20',cosine_distance_sorted[:20],cosine_distance_sorted[-20:])\n",
    "\n",
    "for size in size_list: \n",
    "    \n",
    "    #pick out samples from target domain\n",
    "    df_to_add = df_target_ids[:size]\n",
    "    labels_to_add = df_target_labels[:size]\n",
    "    \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,df_to_add.reviewText])\n",
    "    temp_two_labels = np.concatenate([dict_train_y[vectKey],labels_to_add])\n",
    "    print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape, temp_two_labels.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "    dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train = dict_transfer_vect[vectKey][dfKey].transform(temp_two_df_reviews)\n",
    "    dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "    dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "    #using vectKey as source, and dfkey as target\n",
    "    source_modelVect = MultinomialNB()\n",
    "    source_modelVect.fit(dict_transfer_train,temp_two_labels)\n",
    "    dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "    acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "    print('for size = %d, accuracy = %0.3f'%(size,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Post sort 606930                                            ghetto!!!\n",
      "756908    must do for mk4 jetta must do for mk4 jetta mu...\n",
      "95674     &#4315;&#4304;&#4306;&#4304;&#4320;&#4312;&#43...\n",
      "749000                              This is not an ashtray.\n",
      "510840                                              Perfict\n",
      "Name: reviewText, dtype: object [ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.\n",
      "  0.  1.] [ 0.  0.  0.  0.  0.] [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.59269652  0.6059804   0.61797067  0.62121062  0.6236347   0.62776251\n",
      "  0.62796823  0.6283241   0.62888674  0.62991426  0.63153037  0.63427282\n",
      "  0.63466891  0.64026683  0.64058714  0.64162127  0.64213629  0.64387865\n",
      "  0.6443244   0.64447924  0.64460033  0.64530098  0.64554432  0.64591038\n",
      "  0.64910041  0.65055726  0.65097559  0.65111097  0.65135626  0.65272297\n",
      "  0.65316347  0.65329914  0.65429758  0.65458493  0.65504334  0.65556655\n",
      "  0.65721259  0.65739707  0.65741248  0.65766283  0.65767606  0.65775367\n",
      "  0.65860505  0.65966041  0.66036275  0.66051536  0.66081586  0.6612493\n",
      "  0.66153631  0.66227055  0.6626593   0.66316862  0.66324027  0.66338482\n",
      "  0.66362483  0.66391205  0.6645137   0.66508616  0.66523437]\n"
     ]
    }
   ],
   "source": [
    "print('\\n Post sort',df_target_ids.reviewText[-5:],df_target_labels[-20:],cosine_distance_sorted[:5],cosine_distance_sorted[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping track of results from test runs\n",
    "With number in train set = 10000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 88.74%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 67.16%\n",
    "    Vocab Size : 38696\n",
    "    \n",
    "With number in train set = 50000 (excl 3 ratings)   \n",
    "    Accuracy on dev set for binary prediction: 91.33%   \n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 69.33% \n",
    "    Vocab Size : ~ ..\n",
    "    \n",
    "With number in train set = 100000 (excl 3 ratings)\n",
    "    Accuracy on dev set for binary prediction: 91.56%   \n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.42%\n",
    "    Vocab Size : 105304\n",
    "\n",
    "With number in train set = 500000, dev set = 150000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 91.73%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.95%\n",
    "    vocab size 307822\n",
    "    \n",
    "With number in train set = 1200000, dev set = 360000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 91.92%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 71.24%\n",
    "    vocab size 674074 (not repeated with correction for vocab)\n",
    "    \n",
    "### Output from trying different pre-processing with the toys review set.\n",
    " \n",
    " Accuracy on dev set for binary prediction: 91.69%\n",
    "classification report naive bayes binary classification \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.70      0.77      0.74     22472\n",
    "        1.0       0.96      0.94      0.95    127528\n",
    "\n",
    "avg / total       0.92      0.92      0.92    150000\n",
    "\n",
    "Accuracy on dev set for binary prediction with count vectorizer: 91.92%\n",
    "classification report naive bayes binary classification with count vectorizer \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.71      0.79      0.75     22472\n",
    "        1.0       0.96      0.94      0.95    127528\n",
    "\n",
    "avg / total       0.92      0.92      0.92    150000\n",
    "\n",
    "Accuracy on dev set for binary prediction with tfidf: 90.13%\n",
    "classification report naive bayes binary classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.90      0.38      0.54     22472\n",
    "        1.0       0.90      0.99      0.94    127528\n",
    "\n",
    "avg / total       0.90      0.90      0.88    150000\n",
    "\n",
    "Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.91%\n",
    "classification report naive bayes multinomial classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          1       0.60      0.74      0.66     13975\n",
    "          2       0.32      0.05      0.09      8497\n",
    "          4       0.42      0.34      0.37     29733\n",
    "          5       0.80      0.87      0.83     97795\n",
    "\n",
    "avg / total       0.68      0.71      0.68    150000\n",
    "\n",
    "### Output from simple ratings prediction with video games review set.\n",
    "\n",
    "train set size : 10000, dev set size : 3000\n",
    "Accuracy on dev set for binary prediction with count vectorizer: 88.93%\n",
    "classification report naive bayes binary classification with count vectorizer \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.77      0.54      0.64       534\n",
    "        1.0       0.91      0.96      0.93      2466\n",
    "\n",
    "avg / total       0.88      0.89      0.88      3000\n",
    "\n",
    "Accuracy on dev set for binary prediction with tfidf: 84.93%\n",
    "classification report naive bayes binary classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.95      0.16      0.28       534\n",
    "        1.0       0.85      1.00      0.92      2466\n",
    "\n",
    "avg / total       0.86      0.85      0.80      3000\n",
    "\n",
    "Using SVM, with Count Vectorizer pre-processing:\n",
    "Accuracy on dev set for binary prediction: 82.20%\n",
    "classification report svm              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.00      0.00      0.00       534\n",
    "        1.0       0.82      1.00      0.90      2466\n",
    "\n",
    "avg / total       0.68      0.82      0.74      3000\n",
    "\n",
    "time taken for SVM 48.42102265357971\n",
    "\n",
    "Using SVM with TFIDF pre-processing:\n",
    "Accuracy on dev set for binary prediction: 82.20%\n",
    "classification report svm              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.00      0.00      0.00       534\n",
    "        1.0       0.82      1.00      0.90      2466\n",
    "\n",
    "avg / total       0.68      0.82      0.74      3000\n",
    "\n",
    "train set size : 100000, dev set size : 30000\n",
    "Accuracy on dev set for binary prediction with count vectorizer: 89.12%\n",
    "classification report naive bayes binary classification with count vectorizer \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.72      0.71      0.71      5728\n",
    "        1.0       0.93      0.93      0.93     24272\n",
    "\n",
    "avg / total       0.89      0.89      0.89     30000\n",
    "\n",
    "Accuracy on dev set for binary prediction with tfidf: 86.04%\n",
    "classification report naive bayes binary classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.91      0.30      0.45      5728\n",
    "        1.0       0.86      0.99      0.92     24272\n",
    "\n",
    "avg / total       0.87      0.86      0.83     30000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for transfer learning from toys to video games\n",
    "number words in training corpus for toys: 63984\n",
    "toys dataset id shapes (100000, 63984) (30000, 63984)\n",
    "number words in training corpus for video games: 98899\n",
    "videos dataset id shapes (100000, 98899) (30000, 98899)\n",
    "number words in training corpus for automobiles: 59468\n",
    "automobile dataset id shapes (100000, 59468) (30000, 59468)\n",
    "number words in training corpus for home and kitchen: 57884\n",
    "home and kitchen dataset id shapes (100000, 57884) (30000, 57884)\n",
    "\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 92.23%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.74      0.74      0.74      4503\n",
    "        1.0       0.95      0.95      0.95     25497\n",
    "\n",
    "avg / total       0.92      0.92      0.92     30000\n",
    "\n",
    "Accuracy on video games dev set for binary prediction with video games naive bayes model: 89.16%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.72      0.71      0.71      5725\n",
    "        1.0       0.93      0.93      0.93     24275\n",
    "\n",
    "avg / total       0.89      0.89      0.89     30000\n",
    "\n",
    "Accuracy on autos dev set for binary prediction with autos naive bayes model: 91.93%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.78      0.61      0.69      4323\n",
    "        1.0       0.94      0.97      0.95     25677\n",
    "\n",
    "avg / total       0.91      0.92      0.92     30000\n",
    "\n",
    "Accuracy on home and kitchen dev set for binary prediction with home and kitchen naive bayes model: 91.37%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.76      0.71      0.73      5072\n",
    "        1.0       0.94      0.96      0.95     24928\n",
    "\n",
    "avg / total       0.91      0.91      0.91     30000\n",
    "\n",
    "### Transfer learning:\n",
    "\n",
    "Accuracy on video games dev set for binary prediction with toys naive bayes model: 86.99%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.66      0.65      0.66      5725\n",
    "        1.0       0.92      0.92      0.92     24275\n",
    "\n",
    "avg / total       0.87      0.87      0.87     30000\n",
    "\n",
    "Accuracy on automobiles dev set for binary prediction with toys naive bayes model: 76.06%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.36      0.88      0.51      4323\n",
    "        1.0       0.97      0.74      0.84     25677\n",
    "\n",
    "avg / total       0.88      0.76      0.79     30000\n",
    "\n",
    "Accuracy on home and kitchen dev set for binary prediction with toys naive bayes model: 85.78%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.55      0.85      0.67      5072\n",
    "        1.0       0.97      0.86      0.91     24928\n",
    "\n",
    "avg / total       0.90      0.86      0.87     30000\n",
    "\n",
    "Accuracy on toys dev set for binary prediction with video games naive bayes model: 91.53%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.76      0.63      0.69      4503\n",
    "        1.0       0.94      0.97      0.95     25497\n",
    "\n",
    "avg / total       0.91      0.92      0.91     30000\n",
    "\n",
    "Accuracy on automobiles dev set for binary prediction with video games naive bayes model: 80.50%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.41      0.77      0.53      4323\n",
    "        1.0       0.96      0.81      0.88     25677\n",
    "\n",
    "avg / total       0.88      0.81      0.83     30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from running Naive Bayes for all 4 dfs, with different train set size.\n",
    "\n",
    "Train data_set size = 50000\n",
    "Number words in training corpus for toys 45973\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 92.46%\n",
    "Number words in training corpus for vid 68303\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 89.37%\n",
    "Number words in training corpus for aut 41130\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.57%\n",
    "Number words in training corpus for hnk 41378\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.43%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 92.5% 91.4% 90.9% 91.2%\n",
    "vid  87.1% 89.4% 86.8% 87.3%\n",
    "aut  76.7% 80.0% 91.6% 84.6%\n",
    "hnk  86.1% 86.5% 90.3% 91.4%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid  aut  hnk\n",
    "toys  0.0%  1.0% 1.6% 1.3%\n",
    "vid   2.2%  0.0% 2.5% 2.1%\n",
    "aut  14.9% 11.5% 0.0% 7.0%\n",
    "hnk   5.3%  4.9% 1.1% 0.0%\n",
    "\n",
    " Train data_set size = 100000\n",
    "Number words in training corpus for toys 64698\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 92.17%\n",
    "Number words in training corpus for vid 98625\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 89.22%\n",
    "Number words in training corpus for aut 59179\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.56%\n",
    "Number words in training corpus for hnk 57706\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.56%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 92.2% 91.3% 91.3% 91.1%\n",
    "vid  86.6% 89.2% 87.4% 87.3%\n",
    "aut  75.4% 78.8% 91.6% 83.6%\n",
    "hnk  85.8% 86.5% 90.9% 91.6%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid  aut  hnk\n",
    "toys  0.0%  0.8% 0.9% 1.0%\n",
    "vid   2.6%  0.0% 1.8% 1.9%\n",
    "aut  16.2% 12.8% 0.0% 8.0%\n",
    "hnk   5.8%  5.1% 0.7% 0.0%\n",
    "\n",
    " Train data_set size = 250000\n",
    "Number words in training corpus for toys 104512\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.92%\n",
    "Number words in training corpus for vid 165841\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 89.01%\n",
    "Number words in training corpus for aut 97914\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.87%\n",
    "Number words in training corpus for hnk 93561\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.58%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 91.9% 91.4% 91.8% 91.3%\n",
    "vid  86.1% 89.0% 88.0% 87.5%\n",
    "aut  72.7% 78.0% 91.9% 83.6%\n",
    "hnk  84.9% 86.3% 91.5% 91.6%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid  aut  hnk\n",
    "toys  0.0%  0.6% 0.1% 0.7%\n",
    "vid   2.9%  0.0% 1.0% 1.6%\n",
    "aut  19.2% 13.8% 0.0% 8.3%\n",
    "hnk   6.7%  5.3% 0.1% 0.0%\n",
    "\n",
    " Train data_set size = 500000\n",
    "Number words in training corpus for toys 151534\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.81%\n",
    "Number words in training corpus for vid 249256\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.99%\n",
    "Number words in training corpus for aut 144802\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 92.06%\n",
    "Number words in training corpus for hnk 137575\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.55%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 91.8% 91.4% 91.9% 91.4%\n",
    "vid  85.9% 89.0% 88.4% 87.9%\n",
    "aut  72.8% 78.7% 92.1% 83.6%\n",
    "hnk  84.5% 86.9% 91.7% 91.6%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut  hnk\n",
    "toys  0.0%  0.4% -0.1% 0.5%\n",
    "vid   3.1%  0.0%  0.6% 1.1%\n",
    "aut  19.3% 13.3%  0.0% 8.5%\n",
    "hnk   7.1%  4.7% -0.2% 0.0%\n",
    "\n",
    " Train data_set size = 1000000\n",
    "Number words in training corpus for toys 224573\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.74%\n",
    "Number words in training corpus for vid 309416\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.89%\n",
    "Number words in training corpus for aut 185933\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 92.03%\n",
    "Number words in training corpus for hnk 204991\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.50%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 91.7% 91.5% 91.9% 91.4%\n",
    "vid  85.8% 88.9% 88.7% 88.0%\n",
    "aut  73.0% 78.6% 92.0% 83.3%\n",
    "hnk  84.4% 86.5% 91.8% 91.5%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut  hnk\n",
    "toys  0.0%  0.3% -0.2% 0.3%\n",
    "vid   3.1%  0.0%  0.2% 0.9%\n",
    "aut  19.0% 13.5%  0.0% 8.7%\n",
    "hnk   7.1%  5.0% -0.3% 0.0%\n",
    "\n",
    "from scipy.stats import entropy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
